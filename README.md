# llama.cpp-Launcher

## Description

This is a tool which run llama.cpp([link](https://github.com/ggml-org/llama.cpp)) quickly and conveniently.

## How to Use

1. install [llama.cpp](https://github.com/ggml-org/llama.cpp/releases).
2. set your `SERVER_DIR` and `MODEL_PATH`.
3. run the batchfile.
4. you can also set `NUM_CTX`, `GPU_LAYERS` according to your CPU threads and GPU VRAM.
